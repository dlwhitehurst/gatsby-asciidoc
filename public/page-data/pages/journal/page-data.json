{"componentChunkName":"component---src-templates-article-js","path":"/pages/journal/","result":{"data":{"asciidoc":{"html":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#_introduction\">1. Introduction</a></li>\n<li><a href=\"#_may_2021\">2. May 2021</a></li>\n<li><a href=\"#_apr_2021\">Apr 2021</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#_apr_20_2021\">.1. Apr 20, 2021</a></li>\n<li><a href=\"#_apr_21_2021\">.2. Apr 21, 2021</a></li>\n<li><a href=\"#_apr_22_2021\">.3. Apr 22, 2021</a></li>\n<li><a href=\"#_apr_23_2021\">.4. Apr 23, 2021</a></li>\n<li><a href=\"#_apr_24_2021\">.5. Apr 24, 2021</a></li>\n<li><a href=\"#_mar_2021\">6. Mar 2021</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#_mar_13_2021\">6.1. Mar 13, 2021</a></li>\n<li><a href=\"#_mar_14_2021\">6.2. Mar 14, 2021</a></li>\n<li><a href=\"#_mar_18_2021\">6.3. Mar 18, 2021</a></li>\n<li><a href=\"#_mar_19_2021\">6.4. Mar 19, 2021</a></li>\n</ul>\n</li>\n<li><a href=\"#_license\">Appendix A: License</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>{https://site.fortytwobinary.com/[Site Homepage]</p>\n</div>\n<div class=\"paragraph\">\n<p><a href=\"https://apache.fortytwobinary.com/lab//welcome.html\">Lab Homepage</a></p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image\"><img src=\"images/vy.png\" alt=\"Company Logo\" height=\"32\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Welcome to the FortyTwoBinary service journal of infrastructure changes\non multiple platforms across our home network. This document is subject\nto great change and will be maintained in a software repository\n<a href=\"https://github.com/fortytwobinary/labdocs\">here</a>.</p>\n</div>\n<div class=\"sidebarblock\">\n<div class=\"content\">\n<div class=\"title\">This document</div>\n<div class=\"paragraph\">\n<p>This document was written using asciidoc markup and the HTML you see is\ngenerated by a tool driven using Python called asciidoctor. This\nInfrastructure Change Journal is a powerful document that can be of great value in the\nevent of data loss, machine crashes, backups, maintenance, installations,\nand troubleshooting.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_introduction\">1. Introduction</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>This document contains my writings on the build-out of a network fortytwobinary.lab\nand the infrastructure to support a Kubernetes environment using 3 Raspberry\nPi small board computers (SBC) to start.</p>\n</div>\n<div class=\"paragraph\">\n<p>The network will host a Gitlab instance as a central repository for source, configuration,\ndocumentation, and reference.</p>\n</div>\n<div class=\"paragraph\">\n<p>The fortytwobinary.lab network is strictly for experimentation and education.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_may_2021\">2. May 2021</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>This is a test again</p>\n</div>\n</div>\n</div>\n<h1 id=\"_apr_2021\" class=\"sect0\">Apr 2021</h1>\n<div class=\"paragraph\">\n<p>I&#8217;ve decided to add entries for each month over the previous month however, specific entries for\nthe month will be in reverse (newest first) order.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_apr_20_2021\">.1. Apr 20, 2021</h3>\n<div class=\"paragraph\">\n<p>I&#8217;ve recently moved the Wiki.js database under K8s management. And, I&#8217;ve also hosted an instance of\nWordpress and it&#8217;s database on K8s too. I wrote backups for the <code>tools</code> repo but while the shell scripts\nrun from kube-master manually, they only simulate success in Jenkins jobs. The backup jobs in Jenkins use SSH\nkube-master (192.168.1.12) but the complex context switching is logging errors as if the script does run\nas ubuntu on the right machine but files needed in the script are not available on that host. The backup\nprocess begins with a simple <code>mysqldump</code> however the entire process is quite complex due to the single\ndatabase pod. In a true production situation, the database would be hosted differently and I would have an\nentirely new set of problems.</p>\n</div>\n<div class=\"paragraph\">\n<p>Please note that both Wordpress and Wiki.js backups are failing even though Jenkins is reporting success and\nalso sending this success to Slack.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_apr_21_2021\">.2. Apr 21, 2021</h3>\n<div class=\"paragraph\">\n<p>I realized tonight that only one of the backups on Jenkins was actually broken. The wordpress shell script needed the entire path to the two files that were being copied to the Kubernetes pod. Both wordpress and wikijs backups did need the tty option removed from the <code>kubectl exec</code> commands. These things were fixed and the scripts pushed to Github. Also, the backups were set to run at 8:35 and 8:40PM (0:35 and 0:40 UTC).</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_apr_22_2021\">.3. Apr 22, 2021</h3>\n<div class=\"paragraph\">\n<p>I built an arm64 docker image of Nexus3 and was successful deploying it to my Kubernetes. I was able to visit <a href=\"https://nexus.fortytwobinary.com\" class=\"bare\">https://nexus.fortytwobinary.com</a> and login as admin. I was not however, able to docker login to the docker registry private on port 5000 using internal IP or external DNS. I plan to revise the service and ingress. I&#8217;ll try the docker login again sometime tonight.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_apr_23_2021\">.4. Apr 23, 2021</h3>\n<div class=\"paragraph\">\n<p>Last night I fixed Nexus3 to serve two endpoints, <a href=\"https://nexus.fortytwobinary.com\" class=\"bare\">https://nexus.fortytwobinary.com</a> and <a href=\"https://docker.fortytwobinary.com\" class=\"bare\">https://docker.fortytwobinary.com</a>. The nexus endpoint provides access using basic authentication into a web portal of Nexus3 overall. The docker endpoint provides access into a Docker registry, ssl-terminated, but ultimately HTTP into a docker service on a container&#8217;s port 5000 (docker-only). I was able to create a Docker registry in Nexus and also login to the new Docker registry via command-line. I pushed two images, one for Jenkins (arm64) and one for Nexus3 (arm64). This was a huge success.</p>\n</div>\n<div class=\"paragraph\">\n<p>The issues that remain for me are:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>/mnt/ext/nexus3 remains file permissions 777</p>\n</li>\n<li>\n<p>Could not host service using YAML. This was accomplished with <code>kubectl expose</code>.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_apr_24_2021\">.5. Apr 24, 2021</h3>\n<div class=\"paragraph\">\n<p>Last night I worked on shell scripts and command-line tools. I cleaned\nup my repositories. This morning I just renamed the site Jenkins build to\nlabddocs-deploy and added an Embedded Build plugin so that any Jenkins\ngit build status can be added to READMEs.</p>\n</div>\n<div class=\"paragraph\">\n<p>Today, I am installing Prometheus on my cluster\nand lens on my macbook pro. Lens is available here <a href=\"https://k8slens.dev/\" class=\"bare\">https://k8slens.dev/</a> and I&#8217;ll discuss the Prometheus install a little later.</p>\n</div>\n<div class=\"paragraph\">\n<p>The prometheus install was done from manifests from someone&#8217;s Git repo.\nI cloned the repo and then created a new folder under my k8s-configs repo\nand copied their files. I did absolutely no tweaking of the manifests. I\napplied the deployment and the service verbatim. I did however, notice\nthat my persistent volumes did not show up just after deployment. But\nlater I saw that they were there.</p>\n</div>\n<div class=\"paragraph\">\n<p>The Lens tool is very nice because it organizes all the K8s objects into\none UI and the pods have pop-up menu selections for shells and logs.</p>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_mar_2021\">6. Mar 2021</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>I&#8217;ll start my journal here with a picture of the devices currently on the\nFortyTwoBinary home (internal) network. Here&#8217;s a snip from the router admin\nshowing the wired and wireless devices currently enabled. I&#8217;ll dive into more\ndetail below.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image\"><img src=\"images/mar-13-2021-attached.PNG\" alt=\"Network attached\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>The two wired machines prefixed with <code>kube-</code> are the two machines at the bottom\nof my Raspberry Pi tower. These two machines are Pi 3 Model Bs. They are currently\nrunning Raspbian-lite (buster 10) on 16GB micro SD cards. The machines above them\nare newer Pi 4 Model B devices.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image\"><img src=\"images/tower.jpg\" alt=\"Tower\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Yes, it&#8217;s a mess but, it&#8217;s a start. Currently, the middle, 192.168.1.7\nor third from the bottom is the first 4B I&#8217;ve purchased. It&#8217;s currently hosting\nGitlab on port 80 and these pages on 8081. This journal page is hosted by an\nApache2 docker image on that middle machine. The machine is currently named\nangry-apache and is connected to the network via wireless adapter.</p>\n</div>\n<div class=\"paragraph\">\n<p>The very top machine, 192.168.1.16 hosts a Bind9 service for the fortytwobinary.int or\nFortyTwoBinary internal (home) network. It is also a Raspberry Pi 4B and connected\nto the network via wireless. His name is uptight-genius because he&#8217;s the anal\nname guy.</p>\n</div>\n<div class=\"paragraph\">\n<p>The second from the top machine 192.168.1.15 or oily-weasel is currently just\nrunning. As part of this Kubernetes on Pi initiative, he&#8217;s just a new Pi 4B\nvolunteer that&#8217;s offered his assistance as a kube-worker.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_mar_13_2021\">6.1. Mar 13, 2021</h3>\n<div class=\"paragraph\">\n<p>Last night I put the tower together, but the newer computers were already hosting\nBind9, Apache, Vault, and Gitlab. I flashed two new micro SD cards with Raspbian\nLite for the two older machines on the bottom of my new tower. These older machines\nwere named today (see playbook) but hostnames and DNS have not been set up due to\nKubernetes changes coming.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_mar_14_2021\">6.2. Mar 14, 2021</h3>\n<div class=\"paragraph\">\n<p>Here are the decisions I&#8217;ve made today. I have two groups of SBCs, 5 raspberry pi\ncomputers (tower) and 3 KM8Ps (octa-core arm64). I currently host Gitlab and Apache\non one of the Pi machines. And another Pi Model 4B is idle. These two will NOT host\nKubernetes. The third Pi Model 4B will be the Kubernetes master and the two Pi Model\n3B machines will be Kubernetes workers.</p>\n</div>\n<div class=\"paragraph\">\n<p>DNS, currently on one of the Pi machines will be moved to one of the KM8P devices\nand a secondary nameserver will be created on another KM8P. I suspect the third KM8P\nwill handle all cron activity and maybe even host NFS storage (for backups). The\nKubernetes initiative will support a shared NFS as well but I think that a 128GB\nmicro SD would be a prime choice for an NFS mount to store backups.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_mar_18_2021\">6.3. Mar 18, 2021</h3>\n<div class=\"paragraph\">\n<p><span class=\"image\"><img src=\"images/images/kube-tower.jpg\" alt=\"Kube-Tower\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Last night, I flashed three new micro SD cards with Ubuntu 20.04 LTS for aarm64,\nupdated, upgraded, installed docker, configured kernel parameters for cgroups,\nconfigured iptables for bridged networking, and then installed Kubernetes on all 3.\nThat was quite an accomplishment. I also initialize kube-master and show a Ready status.</p>\n</div>\n<div class=\"paragraph\">\n<p>I ran across some things that require some further education. These are listed below:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>before initialization I should have found the kubeadm version before making the initialization\ncommand. (TODO)</p>\n</li>\n<li>\n<p>I picked or just copied a CIDR choice and I have no clue how this is used or why it was chosen. (TODO)</p>\n</li>\n<li>\n<p>After initialization, it seemed as though kube-master was running as a control-plane node however, <code>kubectl get nodes</code> showed status as Not Ready. I fixed this by creating a kube-flannel.yaml manifest but I never thought that just copying off the Github site would have worked. It did! And, now `kubectl get nodes' shows status Ready.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_mar_19_2021\">6.4. Mar 19, 2021</h3>\n<div class=\"paragraph\">\n<p><span class=\"image\"><img src=\"images/images/frankie.jpg\" alt=\"Frankie\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Last night, I added a NAS or Network Attached Storage to the tower which I&#8217;ve aptly named Frankie, short for Frankenstein. I also created flashed two more 16GB micro-SD cards with Ubuntu 20.04 and re-imaged tower-1 and tower-2. Tower-1 was the apache web server and my Gitlab instance. I moved the repos to public Github. I don&#8217;t really have anything to hide and I like having my code on Github and well-protected.</p>\n</div>\n<div class=\"paragraph\">\n<p>The NFS went well for kube-master and workers 1 and 2. Hosting and client operations all were successful however, new workers 3 and 4 won&#8217;t auto-mount. Something is NOT calling the <code>/etc/fstab</code> file so the mount is not created at /mnt/ext.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_license\">Appendix A: License</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>This document is licensed by the Apache License version 2.0. Currently,\nthe content in this document is being kept from the public however, in\nthe event the material contained here is willingly shared with\nothers, the license will remain unchanged and will convey with the\ntransference of the material.</p>\n</div>\n<div class=\"paragraph\">\n<p>Apache License\nVersion 2.0, January 2004\n<a href=\"http://www.apache.org/licenses/\" class=\"bare\">http://www.apache.org/licenses/</a></p>\n</div>\n<div class=\"paragraph\">\n<p>A copy has also been provided with this software repository.</p>\n</div>\n<div class=\"paragraph\">\n<p>Copyright &#169; 2021 David L Whitehurst.</p>\n</div>\n</div>\n</div>","document":{"title":"Infrastructure Journal","subtitle":"","main":"Infrastructure Journal"},"revision":null,"author":{"fullName":"David L. Whitehurst","firstName":"David","lastName":"Whitehurst","middleName":"L.","authorInitials":"DLW","email":""}}},"pageContext":{"id":"f811429b-39e6-5c4c-bc01-5536100cd36a"}},"staticQueryHashes":[]}